"{\"class_name\": \"Tokenizer\", \"config\": {\"num_words\": 100000, \"filters\": \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\", \"lower\": true, \"split\": \" \", \"char_level\": false, \"oov_token\": \"<OOV>\", \"document_count\": 60000, \"word_counts\": \"{\\\"no\\\": 19989, \\\"si\\\": 11, \\\"n\\\": 19989, \\\"o\\\": 19989, \\\"s\\\": 11, \\\"i\\\": 11}\", \"word_docs\": \"{\\\"no\\\": 19989, \\\"si\\\": 11, \\\"n\\\": 19989, \\\"o\\\": 19989, \\\"s\\\": 11, \\\"i\\\": 11}\", \"index_docs\": \"{\\\"2\\\": 19989, \\\"3\\\": 19989, \\\"4\\\": 19989, \\\"5\\\": 11, \\\"6\\\": 11, \\\"7\\\": 11}\", \"index_word\": \"{\\\"1\\\": \\\"<OOV>\\\", \\\"2\\\": \\\"no\\\", \\\"3\\\": \\\"n\\\", \\\"4\\\": \\\"o\\\", \\\"5\\\": \\\"si\\\", \\\"6\\\": \\\"s\\\", \\\"7\\\": \\\"i\\\"}\", \"word_index\": \"{\\\"<OOV>\\\": 1, \\\"no\\\": 2, \\\"n\\\": 3, \\\"o\\\": 4, \\\"si\\\": 5, \\\"s\\\": 6, \\\"i\\\": 7}\"}}"