"{\"class_name\": \"Tokenizer\", \"config\": {\"num_words\": 100000, \"filters\": \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\", \"lower\": true, \"split\": \" \", \"char_level\": false, \"oov_token\": \"<OOV>\", \"document_count\": 20000, \"word_counts\": \"{\\\"funcionamiento\\\": 7835, \\\"inversi\\\\u00f3n\\\": 11961, \\\"nodefinido\\\": 204}\", \"word_docs\": \"{\\\"funcionamiento\\\": 7835, \\\"inversi\\\\u00f3n\\\": 11961, \\\"nodefinido\\\": 204}\", \"index_docs\": \"{\\\"3\\\": 7835, \\\"2\\\": 11961, \\\"4\\\": 204}\", \"index_word\": \"{\\\"1\\\": \\\"<OOV>\\\", \\\"2\\\": \\\"inversi\\\\u00f3n\\\", \\\"3\\\": \\\"funcionamiento\\\", \\\"4\\\": \\\"nodefinido\\\"}\", \"word_index\": \"{\\\"<OOV>\\\": 1, \\\"inversi\\\\u00f3n\\\": 2, \\\"funcionamiento\\\": 3, \\\"nodefinido\\\": 4}\"}}"